<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="DiffSHEG: A Diffusion-Based Approach for Real-Time Speech-driven Holistic 3D Expression and Gesture Generation.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>DiffSHEG: A Diffusion-Based Approach for Real-Time Speech-driven Holistic 3D Expression and Gesture Generation</title>

 
  <!-- Google tag (gtag.js) -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-QLX02N2YBT"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-QLX02N2YBT');
  </script> -->
  <!-- <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css"> -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/teaser.jpg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>



<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">DiffSHEG: A Diffusion-Based Approach for Real-Time Speech-driven Holistic 3D Expression and Gesture Generation</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://jeremycjm.github.io">Junming Chen</a><sup>1,2</sup>,</span>
            <span class="author-block">
              <a href="http://liuyunfei.net/">Yunfei Liu</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=mt5mvZ8AAAAJ&hl=en&inst=1381320739207392350">Jianan Wang</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://ailingzeng.site/">Ailing Zeng</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://yu-li.github.io/">Yu Li</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://cqf.io">Qifeng Chen</a><sup>1</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>
              <a href="https://hkust.edu.hk/">HKUST</a>, 
            </span>
            <span class="author-block"><sup>2</sup>
              <a href="https://www.idea.edu.cn/">International Digital Economy Academy (IDEA)</a>
            </span>
          </div>

          <!-- <div class="is-size-5 publication-authors">
            <span class="author-block">
              CVPR 2024
            </span>
          </div> -->

          <h4 class="title is-4">CVPR 2024</h4>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2401.04747"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=HFaSd5do-zI"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/JeremyCJM/DiffSHEG"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<!-- CJM BEAT -->
<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/beat/res_2_scott_0_2_2.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/beat/res_2_scott_0_81_81.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/beat/2_scott_3_ours.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/beat/res_2_scott_0_4_4.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
            <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/beat/res_2_scott_0_95_95.mp4"
                      type="video/mp4">
            </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/beat/res_2_scott_0_6_6.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/beat/res_2_scott_0_7_7.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/beat/res_2_scott_0_8_8.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/beat/res_2_scott_0_73_73.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/beat/res_2_scott_0_111_111.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/beat/4_lawrence_81.mp4"
                    type="video/mp4">
          </video>
        </div>
        <!-- <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/beat/res_6_carla_0_95_95.mp4"
                    type="video/mp4">
          </video>
        </div> -->
      </div>
    </div>
  </div>
</section>
<!-- CJM BEAT END -->



<!-- CJM SHOW -->
<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/show/214545-00_10_58-00_11_08.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/show/97743-00_01_11-00_01_21.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/show/103358-00_08_57-00_09_07.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/show/103369-00_02_05-00_02_15.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/show/6302-00_02_04-00_02_14.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/show/105965-00_02_41-00_02_51.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/show/72865-00_01_47-00_01_57.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/show/116234-00_00_41-00_00_51.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/show/116866-00_00_50-00_01_00.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/show/216949-00_00_05-00_00_15.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- CJM SHOW END -->

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
          We propose <b><span class="dnerf">DiffSHEG</span></b>, a <b>Diff</b>usion-based approach for <b>S</b>peech-driven 
          <b>H</b>olistic 3D <b>E</b>xpression and <b>G</b>esture generation with arbitrary length. 
          While previous works focused on co-speech gesture or expression generation individually, 
          the joint generation of synchronized expressions and gestures remains barely explored. 
          To address this, our diffusion-based co-speech motion generation transformer enables uni-directional 
          information flow from expression to gesture, facilitating improved matching of joint expression-gesture 
          distributions. Furthermore, we introduce an outpainting-based sampling strategy for arbitrary long 
          sequence generation in diffusion models, offering flexibility and computational efficiency. Our method 
          provides a practical solution that produces high-quality synchronized expression and gesture generation 
          driven by speech. Evaluated on two public datasets, our approach achieves state-of-the-art performance 
          both quantitatively and qualitatively. Additionally, a user study confirms the superiority of DiffSHEG 
          over prior approaches. By enabling the real-time generation of expressive and synchronized motions, 
          DiffSHEG showcases its potential for various applications in the development of digital humans and 
          embodied agents.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->


    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Demo Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/HFaSd5do-zI?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>


<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Nerfies</span> turns selfie videos from your phone into
        free-viewpoint
        portraits.
      </h2>
    </div>
  </div>
</section> -->


<!-- Framework -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-3">Framework</h2>
    </div>
    <div class="columns is-centered">
      <div class="content has-text-justified">
        <br/>
        <p>
          <b>DiffSHEG framework overview.</b> <b>Left:</b> Audio Encoders and 
          UniEG-Transformer Denoiser. Given an audio clip, we encode the audio into 
          a low-level feature Mel-Spectrogram and a high-level HuBERT feature. The 
          audio features are concatenated with other optional conditions, such as 
          text, and then fed into the UniEG Transformer Denoiser. The denoising 
          block fuses the conditions with noisy motion at diffusion step t and feeds 
          it into style-aware transformers to get the predicted noises. The uni-directional 
          condition flow is enforced from expression to gesture. <b>Right:</b> 
          The detailed architecture of style-aware Transformer encoder and motion-condition 
          fusion residual block.
        </p>
      </div>
    </div>
    <div class="content has-text-centered">
      <img src="./static/images/framework.png"
                          class="image"
                          alt="image."
                          height="100%"
                          width="100%"/>
    </div>
  </div>
</section>


<!-- Arbitrary-long Sampling -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-3">Arbitrary-long Sampling</h2>
    </div>
    <div class="columns is-centered">
      <div class="content has-text-justified">
        <br/>
        <p>
          We propose Fast Outpainting-based Partial Autoregressive Sampling (<b>FOPPAS</b>).
          Instead of conditioning the model on previous frames during training, FOPPAS realizes 
          the arbitrary-long sampling via outpainting at the test time without training, which 
          has more flexibility and less computation waste.
          The following algorithm describes the single clip pass of our FOPPAS method. 
        </p>
      </div>
    </div>
    <div class="content has-text-centered">
      <img src="./static/images/algorithm.jpg"
                          class="image"
                          alt="image."
                          style="margin: 0 auto"
                          height="40%"
                          width="40%"/>
    </div>
  </div>
</section>


<!-- User Study -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-3">User Study</h2>
    </div>
    <div class="columns is-centered">
      <div class="content has-text-justified">
        <br/>
        <p>
          The figure shows user preference percentage in terms of four metrics: realism, 
          gesture-speech synchronism, expression-speech synchronism, and motion 
          diversity. In both datasets and all metrics, our method is dominantly 
          preferred. DSG and DG are the abbreviations of DiffuseStyleGesture 
          and DiffuseGesture.
        </p>
      </div>
    </div>
    <div class="content has-text-centered">
      <img src="./static/images/user_study.jpg"
                          class="image"
                          alt="image."
                          height="100%"
                          width="100%"/>
    </div>
  </div>
</section>

<!-- Quantitative Comparison -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-3">Quantitative Comparison</h2>
    </div>
    <div class="columns is-centered">
      <div class="content has-text-justified">
        <br/>
        <p>
          On the BEAT dataset, we compare our DiffSHEG with CaMN, DiffGesture, 
          DiffuseStyleGesture (DSG) and LDA with audio and person ID as input. 
          Note that the baseline methods are originally for gesture generation 
          solely, and we apply the same procedure independently for expression 
          generation. On the SHOW dataset, we compare with 
          LS3DCG and TalkSHOW. The ablation studies are conducted 
          on both datasets to demonstrate the effectiveness of our UniEG-Transformer 
          design. Note that we use SRGR on the BEAT dataset and PCM on SHOW dataset. 
          *: indicates that the results are computed using the pre-trained checkpoints 
          provided by authors of TalkSHOW. 
        </p>
      </div>
    </div>
    <div class="content has-text-centered">
      <img src="./static/images/quantitative_results.jpg"
                          class="image"
                          alt="image."
                          height="100%"
                          width="100%"/>
    </div>
  </div>
</section>

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{chen2024diffsheg,
      title     = {DiffSHEG: A Diffusion-Based Approach for Real-Time Speech-driven Holistic 3D Expression and Gesture Generation},
      author    = {Chen, Junming and Liu, Yunfei and Wang, Jianan and Zeng, Ailing and Li, Yu and Chen, Qifeng},
      booktitle = {CVPR},
      year      = {2024}
    }</code></pre>
  </div>
</section>






<footer class="footer">
  <div class="container">
    <!-- <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div> -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons 4.0 Licence</a>. Website template credit: <a
            href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
  <div class="columns is-centered">
    <a href='https://clustrmaps.com/site/1by4t'  title='Visit tracker'><img src='//clustrmaps.com/map_v2.png?cl=ffffff&w=a&t=n&d=9hNrBG4KbEDNqnmfVSyvFZakGAbmBTFgj8waSevLgVk&co=f2f2f2'/></a>
  </div>
</footer>




</body>
</html>
